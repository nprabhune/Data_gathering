# Data_gathering

# Topos Data Engineer Intern Assignment 

## Libraries Used: 
- requests
- BeautifulSoup
- urllib
- re
- pandas
- time

## Description
This is a scraper in Python, that initially takes the names of the major cities in the United States from a table, and then goes to the Wikipedia page of each city to collect information about that particular city. The data collected from the pages is then stored and written to a CSV file. 

## To run the scraper:
Import the notebook in Jupyter. Please make sure all the dependencies listed above are installed. Run each cell in order. Finally, CSV is written to the same directory as where the notebook is present. 
